# Super Resolution Generative Adversarial Network (SRGAN)

* Here is an implementation of paper [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802) on Brain Tumor dataset.
* SRGAN uses the GAN to produce the high resolution images from the low resolution images. In this implementation, for training, the original 512 X 512 high resolution image is downsampled into low resolution image using Gaussian blur followed by resizing it to 128 X 128. A Generator is used to generate 512 X 512 images from 128 X 128 images and a discriminator is used to distinguish the generated images from the HR images.
* Brain tumor dataset used here is obtained from [figshare](https://figshare.com/articles/dataset/brain_tumor_dataset/1512427). This dataset contains 3064 T1-weighted contrast-enhanced images from 233 patients with three kinds of brain tumor: meningioma (708 slices),  glioma (1426 slices), and pituitary tumor (930 slices) with mask for tumor region. This data is in matlab format and file consists of following fields: -
    * Patient ID
    * Label
    * Image Array
    * Tumor Border (It was generated by manually delineating the tumor border)
    * Tumor Mask
![BT Images](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Presentation/img_feb/img.png?raw=true)
![BT Image Masks](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Presentation/img_feb/mask.png?raw=true)
* From the above images we can clearly see that, we have mask for tumor region, which makes out task easy to separate out tumor region and work on it.
## GAN Network Architecture
![Network](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/network.jpg?raw=true)
* Above is the architecture of generator and discriminator used in the reference paper. k9n64s1 signifies kernel of size 9, 64 channels and stride of 1. Residual blocks are used in the discriminator. Two new concepts which are used in the network architecture are PRelu and PixelShuffler.
* **PRelu:** is a kind of leakyRelu where instead of a predefined slope of 0.01, it makes it parameter for the neural network to itself decide the value of slope. y=ax when x<0 and y=x when x> 0 where a is the parameter to be determined by the network.
* **PixelShuffling:** rearrange the tensor of shape (N,C,H,W) into (N,C/rr,Hr,W*r) where r is the shuffling factor. It basically convert the depth(channel) into the space(height and width). In Generator, pixelshuffling is used to upsample the images size.

## Generator
* 7 Convolution blocks Each block with the same number of filters
* PReLU with ( α = 0.2 ) is used as activation layer
* 2 PixelShuffler layers for upsampling - PixelShuffler is feature map upscaling
* Skip connections are used to achieve faster convergence

## Discriminator
* 16 Residual blocks Each block with increasing number of filters
* LeakyReLU with ( α = 0.2 ) is used as activation layer
* 2 Dense layers

## Network Flow
![Model Working FLow Chart](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/SRGAN%20Flow.png?raw=true)

## Results
![Epoch Loss](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/srgan_loss.png?raw=true)
![Results](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/output.png?raw=true)

## Loss Functions
![loss functions](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/GAN%20Loss.png?raw=true)

## Evaluation Mertices

![MSE](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/MSE.png?raw=true)
![PSNR](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/PSNR.png?raw=true)
![SSIM](https://github.com/mayank1101/Master-Thesis-Work/blob/main/Implementation%20Work/SRGAN/img/SSIM.png?raw=true)
